
# ğŸ™ï¸ Voice of Truth â€” Audio Deepfake Detection

> Detecting audio deepfakes using spectrograms, CNN, and SHAP explainability.


## ğŸ“Œ Overview
Audio deepfakes pose a serious threat in misinformation, fraud, and digital security.  
This project implements a **deep learningâ€“based system** to detect whether a given audio clip is **real or fake**.  

âœ… Converts audio into spectrograms  
âœ… Trains a **CNN classifier**  
âœ… Uses **SHAP** to explain predictions  
âœ… Provides a **Streamlit demo app** for testing audio clips  

---

## ğŸ—ï¸ Architecture

![Architecture](assets/architecture.png)  
*(Example: Audio â†’ Spectrogram â†’ CNN â†’ Classification + SHAP)*

1. **Preprocessing** â€“ Convert `.wav` into mel-spectrograms.  
2. **Modeling** â€“ Train a CNN to classify *real* vs *fake*.  
3. **Explainability** â€“ Apply SHAP for local + global interpretation.  
4. **Deployment** â€“ Streamlit app to upload audio and see results live.  

---

## ğŸ“Š Example Results

| Input Audio | Prediction | Confidence | 
|-------------|------------|------------|------------------|
| `real_01.wav` | âœ… Real | 0.92 | 
| `fake_05.wav` | âŒ Fake | 0.88 | 

ğŸ”¬ Technologies Used

Python 3.10
Librosa â€“ audio processing

TensorFlow / PyTorch â€“ deep learning models

SHAP â€“ explainability

Streamlit â€“ web demo

Scikit-learn â€“ metrics, preprocessing

ğŸ“ˆ Performance

Dataset: SceneFake / FoR (Kaggle)

Best model: CNN with spectrogram input

Accuracy: ~91% on test set

SHAP explanations highlight frequency-time regions influencing predictions

## ğŸ“¦ Dataset

This repository includes a `archive(1)` folder containing ~4000 audio clips for training and evaluation.  
The dataset covers **English** and other language samples, each labeled as **Real** or **Fake**.  named 'lang'


To run program streamlit run audio_deepfak_ui.py



